---
title: "Scorelabs Cloud"
date: 2025-10-30
description: "Managed cloud service for cost-efficient LLM inference built on OpenStack + Kubernetes."
summary: "Building a unified, multi-data-center OpenStack platform for CPU-based LLM inference and cloud services."
draft: false
tags: ["openstack", "llm", "kaas", "automation"]
cover:
  image: "/images/covers/scorelabs-cloud.webp"
  alt: "Scorelabs Cloud architecture diagram"
  caption: "Scorelabs Cloud — bridging OpenStack and Kubernetes for AI workloads."
---

**Scorelabs Cloud** is an R&D initiative to unify multiple OpenStack clusters into a managed, multi-tenant platform.  
It delivers **Kubernetes-as-a-Service**, **storage**, and **AI inference APIs** over on-prem infrastructure — optimized for **CPU inference** to reduce GPU dependency and cost.

### Core Features
- Multi-region federation using OpenStack Magnum and Kuryr  
- CPU-based inference endpoints for LLM models  
- Self-service tenant provisioning with quota isolation  
- Ansible-driven automation for reproducible deployments  

**Tech stack:** OpenStack Ansible · Kubernetes · Helm · Ceph · OVN · Terraform · Python  

